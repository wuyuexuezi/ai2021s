{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 作业3：深度学习框架实践"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本次作业将练习深度学习框架的使用，大部分内容用 PyTorch 实现。第1题利用卷积层和全连接层实现手写数字的识别，第2题利用 RNN 来实现英文名的自动生成，第3题是算法题，利用卷积运算实现任意大整数的乘法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第1题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 目标：通过对 MNIST 数据进行训练，构建一个简单的图像分类模型，对图片中的数字进行识别。你将利用该模型对自己真实手写出的数字进行预测，观察模型效果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 主要步骤：获取数据，创建模型结构，定义损失函数，编写训练循环，实施预测。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 获取数据。我们使用知名的 MNIST 数据集，它可以从 PyTorch 中利用工具函数下载得到。原始的 MNIST 数据训练集大小为60000，我们随机抽取其中的10000个观测进行简单的训练。以下函数会在当前目录建立一个名为 data 的文件夹，其中会包含下载得到的数据集。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**注意：请在任何程序的最开始加上随机数种子的设置。请保持这一习惯。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "np.random.seed(123)\n",
    "torch.manual_seed(123)\n",
    "\n",
    "mnist = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "loader = DataLoader(mnist, batch_size=200, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们一次性取出随机抽取到的10000个观测，其中 x 是图片数据，y 是图片对应的数字。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一个习惯性动作是查看数据的大小和维度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200])\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以利用下面的函数展示图片的内容。如选择第一张图片，先将其转换成 Numpy 数组，再绘制图形："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = x[0].squeeze().cpu().numpy()\n",
    "print(img.shape)\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来请你选择5个你喜欢的数字（10000以下），然后取出对应位置的图片，并画出它们的内容。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot five digits here   可能软件有问题 这一个和上一个都跑不出来\n",
    "import matplotlib.pyplot as plt\n",
    "img1 = x[1].squeeze().cpu().numpy()\n",
    "img2 = x[2].squeeze().cpu().numpy()\n",
    "img3 = x[3].squeeze().cpu().numpy()\n",
    "img4 = x[4].squeeze().cpu().numpy()\n",
    "img5 = x[5].squeeze().cpu().numpy()\n",
    "plt.figure()\n",
    "\n",
    "plt.subplot(1,5,1)\n",
    "plt.imshow(img1, cmap=\"gray\")\n",
    "plt.subplot(1,5,2)\n",
    "plt.imshow(img2, cmap=\"gray\")\n",
    "plt.subplot(1,5,3)\n",
    "plt.imshow(img3, cmap=\"gray\")\n",
    "plt.subplot(1,5,4)\n",
    "plt.imshow(img4, cmap=\"gray\")\n",
    "plt.subplot(1,5,5)\n",
    "plt.imshow(img5, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 搭建模型。我们搭建一个类似于 LeNet-5 的网络，结构如下："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://pic1.zhimg.com/80/v2-82eabb4c17e90d467197d013f7629f3c_720w.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们需要创建2个卷积层、2个汇聚层（池化层）和2个全连接层，**暂时忽略所有的激活函数**。所有隐藏层的函数细节都可以在[官方文档](https://pytorch.org/docs/stable/nn.html)中按分类找到。每一个隐藏层本质上都是将一个数组变换成另一个数组的函数，因此为了确认编写的模型是正确的，可以先用一个小数据进行测试，观察输入和输出的维度。例如，我们先取出前10个观测，此时输入的维度是 `[10, 1, 28, 28]`："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1, 28, 28])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "smallx = x[0:10]\n",
    "smally = y[0:10]\n",
    "print(smallx.shape)\n",
    "print(smally.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来创建第1个卷积层，并测试输出的维度。注意到我们可以直接将隐藏层当成一个函数来调用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 20, 24, 24])\n"
     ]
    }
   ],
   "source": [
    "conv1 = torch.nn.Conv2d(in_channels=1, out_channels=20, kernel_size=5, stride=1)\n",
    "res = conv1(smallx)\n",
    "print(res.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到，输出的维度为 `[20, 24, 24]`（不包括第1位的数据批次维度），与之前图中的结果吻合。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，请按照图中提示编写层对象 `pool1`、`conv2`、`pool2`、`fc1` 和 `fc2`，并顺次测试输入与输出的维度，使其与上图匹配。注意，在将一个大小为 `[10, 50, 4, 4]` 的数组（假设叫 `somearray`）传递给 `fc1` 之前，需要先将其变形为只有两个维度的数组，做法是 `somearray.view(-1, 50*4*4)`，其中 -1 表示该位置的大小不变。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "pool1 = ...\n",
    "res = pool1(res)\n",
    "print(res.shape)\n",
    "\n",
    "conv2 = ...\n",
    "res = conv2(res)\n",
    "print(res.shape)\n",
    "\n",
    "pool2 = ...\n",
    "res = pool2(res)\n",
    "print(res.shape)\n",
    "\n",
    "fc1 = ...\n",
    "res = fc1(res.view(-1, 50 * 4 * 4))\n",
    "print(res.shape)\n",
    "\n",
    "fc2 = ...\n",
    "res = fc2(res)\n",
    "print(res.shape)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 20, 12, 12])\n"
     ]
    }
   ],
   "source": [
    "pool1 = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "res = pool1(res)\n",
    "print(res.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 50, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "conv2 = torch.nn.Conv2d(in_channels=20, out_channels=50, kernel_size=5, stride=1)\n",
    "res = conv2(res)\n",
    "print(res.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 50, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "pool2 = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "res = pool2(res)\n",
    "print(res.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 800])\n"
     ]
    }
   ],
   "source": [
    "res = res.view(-1, 50*4*4)\n",
    "print(res.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 500])\n"
     ]
    }
   ],
   "source": [
    "fc1 = torch.nn.Linear(50*4*4, 500)\n",
    "res = fc1(res)\n",
    "print(res.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 10])\n"
     ]
    }
   ],
   "source": [
    "fc2 = torch.nn.Linear(500, 10)\n",
    "res = fc2(res)\n",
    "print(res.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. 创建模型类。在确保隐藏层维度都正确后，将所有的隐藏层封装到一个模型类中，其中模型结构在 `__init__()` 中定义，具体的计算过程在 `forward()` 中实现。此时需要加入激活函数。在本模型中，**请在 `conv1`、`conv2` 和 `fc1` 后加入 ReLU 激活函数，并在 `fc2` 后加入 Softmax 激活函数**。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "class MyModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = ...\n",
    "        self.pool1 = ...\n",
    "        self.conv2 = ...\n",
    "        self.pool2 = ...\n",
    "        self.fc1 = ...\n",
    "        self.fc2 = ...\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.pool1(x)\n",
    "        ...\n",
    "        return x\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(in_channels=1, out_channels=20, kernel_size=5, stride=1)\n",
    "        self.pool1 = torch.nn.MaxPool2d(2, stride=2)\n",
    "        self.conv2 = torch.nn.Conv2d(in_channels=20, out_channels=50, kernel_size=5, stride=1)\n",
    "        self.pool2 = torch.nn.MaxPool2d(2, stride=2)\n",
    "        self.fc1 = torch.nn.Linear(50*4*4, 500)\n",
    "        self.fc2 = torch.nn.Linear(500, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.pool2(x)\n",
    "        x = x.view(-1, 50*4*4)\n",
    "        x = self.fc1(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = torch.nn.functional.softmax(x, dim=1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "再次测试输入输出的维度是否正确。如果模型编写正确，输出的维度应该是 `[10, 10]`，且输出结果为0到1之间的概率值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 10])\n",
      "tensor([[0.0992, 0.0989, 0.0982, 0.1089, 0.0943, 0.0912, 0.0996, 0.1020, 0.1021,\n",
      "         0.1056],\n",
      "        [0.0997, 0.1004, 0.0978, 0.1085, 0.0938, 0.0907, 0.0982, 0.1045, 0.1020,\n",
      "         0.1045],\n",
      "        [0.0990, 0.0993, 0.0979, 0.1081, 0.0913, 0.0921, 0.0976, 0.1088, 0.1030,\n",
      "         0.1031],\n",
      "        [0.0955, 0.0996, 0.1010, 0.1081, 0.0931, 0.0913, 0.0988, 0.1044, 0.1031,\n",
      "         0.1051],\n",
      "        [0.0995, 0.0988, 0.0985, 0.1091, 0.0919, 0.0918, 0.0980, 0.1059, 0.1017,\n",
      "         0.1049],\n",
      "        [0.0977, 0.0994, 0.0996, 0.1073, 0.0924, 0.0922, 0.1018, 0.1019, 0.1040,\n",
      "         0.1038],\n",
      "        [0.0972, 0.1011, 0.1010, 0.1062, 0.0931, 0.0908, 0.1006, 0.1048, 0.1037,\n",
      "         0.1016],\n",
      "        [0.0996, 0.0984, 0.0987, 0.1068, 0.0904, 0.0900, 0.0992, 0.1076, 0.1020,\n",
      "         0.1075],\n",
      "        [0.0972, 0.0998, 0.1012, 0.1084, 0.0925, 0.0905, 0.1022, 0.1014, 0.1023,\n",
      "         0.1045],\n",
      "        [0.0979, 0.0998, 0.0985, 0.1080, 0.0959, 0.0910, 0.0979, 0.1049, 0.1027,\n",
      "         0.1033]], grad_fn=<SoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(123)\n",
    "torch.manual_seed(123)\n",
    "\n",
    "model = MyModel()\n",
    "pred = model(smallx)\n",
    "print(pred.shape)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pred` 的每一行加总为1，其中每一个元素代表对应类别的预测概率。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们还可以直接打印模型对象，观察隐藏层的结构："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyModel(\n",
      "  (conv1): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(20, 50, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=800, out_features=500, bias=True)\n",
      "  (fc2): Linear(in_features=500, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. 损失函数。对于分类问题，损失函数通常选取为负对数似然函数。在 PyTorch 中，可以使用 `torch.nn.NLLLoss` 来完成计算。其用法是先定义一个损失函数对象，然后在预测值和真实标签上调用该函数对象。注意：损失函数对象的第一个参数是预测概率的**对数值**，第二个参数是真实的标签。[文档说明](https://pytorch.org/docs/stable/generated/torch.nn.NLLLoss.html)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.323056221008301\n"
     ]
    }
   ],
   "source": [
    "lossfn = torch.nn.NLLLoss()\n",
    "loss = lossfn(torch.log(pred), smally)\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. 利用课上介绍的循环模板和代码示例，对模型进行迭代训练。对于本数据，选取 mini-batch 大小为200，共遍历数据10遍，优化器选为 Adam，学习率为0.001。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USE_CUDA = torch.cuda.is_available()\n",
    "USE_CUDA = False\n",
    "np.random.seed(123)\n",
    "torch.manual_seed(123)\n",
    "model = MyModel()\n",
    "if USE_CUDA:\n",
    "    torch.cuda.manual_seed(123)  \n",
    "if USE_CUDA:\n",
    "    model = model.cuda()\n",
    "    \n",
    "\n",
    "epochs = 10\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, batch 0, loss = 2.3035948276519775\n",
      "epoch 0, batch 10, loss = 1.4207230806350708\n",
      "epoch 0, batch 20, loss = 0.5895281434059143\n",
      "epoch 0, batch 30, loss = 0.32067301869392395\n",
      "epoch 0, batch 40, loss = 0.4025203287601471\n",
      "epoch 0, batch 50, loss = 0.237248957157135\n",
      "epoch 0, batch 60, loss = 0.3056967258453369\n",
      "epoch 0, batch 70, loss = 0.18267740309238434\n",
      "epoch 0, batch 80, loss = 0.2878718078136444\n",
      "epoch 0, batch 90, loss = 0.2376011461019516\n",
      "epoch 0, batch 100, loss = 0.14671562612056732\n",
      "epoch 0, batch 110, loss = 0.2455405592918396\n",
      "epoch 0, batch 120, loss = 0.19403783977031708\n",
      "epoch 0, batch 130, loss = 0.11745459586381912\n",
      "epoch 0, batch 140, loss = 0.09421530365943909\n",
      "epoch 0, batch 150, loss = 0.12201116234064102\n",
      "epoch 0, batch 160, loss = 0.10544349998235703\n",
      "epoch 0, batch 170, loss = 0.15340441465377808\n",
      "epoch 0, batch 180, loss = 0.09472627937793732\n",
      "epoch 0, batch 190, loss = 0.14323243498802185\n",
      "epoch 0, batch 200, loss = 0.09068030118942261\n",
      "epoch 0, batch 210, loss = 0.07099581509828568\n",
      "epoch 0, batch 220, loss = 0.11171784996986389\n",
      "epoch 0, batch 230, loss = 0.10134264081716537\n",
      "epoch 0, batch 240, loss = 0.059056658297777176\n",
      "epoch 0, batch 250, loss = 0.0792105421423912\n",
      "epoch 0, batch 260, loss = 0.10662413388490677\n",
      "epoch 0, batch 270, loss = 0.07210805267095566\n",
      "epoch 0, batch 280, loss = 0.05564124137163162\n",
      "epoch 0, batch 290, loss = 0.04667775705456734\n",
      "epoch 1, batch 0, loss = 0.07405810803174973\n",
      "epoch 1, batch 10, loss = 0.08666685223579407\n",
      "epoch 1, batch 20, loss = 0.10368020832538605\n",
      "epoch 1, batch 30, loss = 0.061605267226696014\n",
      "epoch 1, batch 40, loss = 0.07884930819272995\n",
      "epoch 1, batch 50, loss = 0.08505848050117493\n",
      "epoch 1, batch 60, loss = 0.06158040091395378\n",
      "epoch 1, batch 70, loss = 0.06747674196958542\n",
      "epoch 1, batch 80, loss = 0.052424777299165726\n",
      "epoch 1, batch 90, loss = 0.09175951033830643\n",
      "epoch 1, batch 100, loss = 0.06715486198663712\n",
      "epoch 1, batch 110, loss = 0.046458106487989426\n",
      "epoch 1, batch 120, loss = 0.036543916910886765\n",
      "epoch 1, batch 130, loss = 0.057819146662950516\n",
      "epoch 1, batch 140, loss = 0.07650154083967209\n",
      "epoch 1, batch 150, loss = 0.04685167223215103\n",
      "epoch 1, batch 160, loss = 0.08586504310369492\n",
      "epoch 1, batch 170, loss = 0.06488585472106934\n",
      "epoch 1, batch 180, loss = 0.06932927668094635\n",
      "epoch 1, batch 190, loss = 0.032024532556533813\n",
      "epoch 1, batch 200, loss = 0.01753159798681736\n",
      "epoch 1, batch 210, loss = 0.1425270140171051\n",
      "epoch 1, batch 220, loss = 0.07217375934123993\n",
      "epoch 1, batch 230, loss = 0.0855318009853363\n",
      "epoch 1, batch 240, loss = 0.046305421739816666\n",
      "epoch 1, batch 250, loss = 0.09288042783737183\n",
      "epoch 1, batch 260, loss = 0.07402461022138596\n",
      "epoch 1, batch 270, loss = 0.0622183233499527\n",
      "epoch 1, batch 280, loss = 0.036515939980745316\n",
      "epoch 1, batch 290, loss = 0.07501909881830215\n",
      "epoch 2, batch 0, loss = 0.03997079282999039\n",
      "epoch 2, batch 10, loss = 0.01931610144674778\n",
      "epoch 2, batch 20, loss = 0.022420313209295273\n",
      "epoch 2, batch 30, loss = 0.033851224929094315\n",
      "epoch 2, batch 40, loss = 0.06754991412162781\n",
      "epoch 2, batch 50, loss = 0.05763881653547287\n",
      "epoch 2, batch 60, loss = 0.07205475121736526\n",
      "epoch 2, batch 70, loss = 0.08505674451589584\n",
      "epoch 2, batch 80, loss = 0.05196899548172951\n",
      "epoch 2, batch 90, loss = 0.0344540998339653\n",
      "epoch 2, batch 100, loss = 0.01632503792643547\n",
      "epoch 2, batch 110, loss = 0.03283290937542915\n",
      "epoch 2, batch 120, loss = 0.026613211259245872\n",
      "epoch 2, batch 130, loss = 0.051677532494068146\n",
      "epoch 2, batch 140, loss = 0.05297965183854103\n",
      "epoch 2, batch 150, loss = 0.042586278170347214\n",
      "epoch 2, batch 160, loss = 0.06434536725282669\n",
      "epoch 2, batch 170, loss = 0.015668407082557678\n",
      "epoch 2, batch 180, loss = 0.047300294041633606\n",
      "epoch 2, batch 190, loss = 0.07216949015855789\n",
      "epoch 2, batch 200, loss = 0.020090211182832718\n",
      "epoch 2, batch 210, loss = 0.011224362999200821\n",
      "epoch 2, batch 220, loss = 0.015073060058057308\n",
      "epoch 2, batch 230, loss = 0.054770804941654205\n",
      "epoch 2, batch 240, loss = 0.04563659057021141\n",
      "epoch 2, batch 250, loss = 0.04176722839474678\n",
      "epoch 2, batch 260, loss = 0.021384960040450096\n",
      "epoch 2, batch 270, loss = 0.0540875643491745\n",
      "epoch 2, batch 280, loss = 0.03298071399331093\n",
      "epoch 2, batch 290, loss = 0.12484581023454666\n",
      "epoch 3, batch 0, loss = 0.014636673964560032\n",
      "epoch 3, batch 10, loss = 0.010139287449419498\n",
      "epoch 3, batch 20, loss = 0.01397253479808569\n",
      "epoch 3, batch 30, loss = 0.03580522909760475\n",
      "epoch 3, batch 40, loss = 0.02829165756702423\n",
      "epoch 3, batch 50, loss = 0.013030728325247765\n",
      "epoch 3, batch 60, loss = 0.07831961661577225\n",
      "epoch 3, batch 70, loss = 0.012568563222885132\n",
      "epoch 3, batch 80, loss = 0.015158477239310741\n",
      "epoch 3, batch 90, loss = 0.03470566123723984\n",
      "epoch 3, batch 100, loss = 0.06844273209571838\n",
      "epoch 3, batch 110, loss = 0.058161139488220215\n",
      "epoch 3, batch 120, loss = 0.05139734596014023\n",
      "epoch 3, batch 130, loss = 0.05297110229730606\n",
      "epoch 3, batch 140, loss = 0.013034721836447716\n",
      "epoch 3, batch 150, loss = 0.05221765860915184\n",
      "epoch 3, batch 160, loss = 0.00967363640666008\n",
      "epoch 3, batch 170, loss = 0.07368119060993195\n",
      "epoch 3, batch 180, loss = 0.03669797256588936\n",
      "epoch 3, batch 190, loss = 0.027293886989355087\n",
      "epoch 3, batch 200, loss = 0.13867072761058807\n",
      "epoch 3, batch 210, loss = 0.037325598299503326\n",
      "epoch 3, batch 220, loss = 0.017391331493854523\n",
      "epoch 3, batch 230, loss = 0.012551367282867432\n",
      "epoch 3, batch 240, loss = 0.013930121436715126\n",
      "epoch 3, batch 250, loss = 0.03837648034095764\n",
      "epoch 3, batch 260, loss = 0.07727806270122528\n",
      "epoch 3, batch 270, loss = 0.049244269728660583\n",
      "epoch 3, batch 280, loss = 0.006320022512227297\n",
      "epoch 3, batch 290, loss = 0.05947154015302658\n",
      "epoch 4, batch 0, loss = 0.038071006536483765\n",
      "epoch 4, batch 10, loss = 0.02291599102318287\n",
      "epoch 4, batch 20, loss = 0.030008122324943542\n",
      "epoch 4, batch 30, loss = 0.009129341691732407\n",
      "epoch 4, batch 40, loss = 0.008070719428360462\n",
      "epoch 4, batch 50, loss = 0.008609270676970482\n",
      "epoch 4, batch 60, loss = 0.016767101362347603\n",
      "epoch 4, batch 70, loss = 0.009168998338282108\n",
      "epoch 4, batch 80, loss = 0.05503542721271515\n",
      "epoch 4, batch 90, loss = 0.026326751336455345\n",
      "epoch 4, batch 100, loss = 0.036600492894649506\n",
      "epoch 4, batch 110, loss = 0.02782493270933628\n",
      "epoch 4, batch 120, loss = 0.01549805048853159\n",
      "epoch 4, batch 130, loss = 0.012580872513353825\n",
      "epoch 4, batch 140, loss = 0.013779920525848866\n",
      "epoch 4, batch 150, loss = 0.00421824911609292\n",
      "epoch 4, batch 160, loss = 0.04431987181305885\n",
      "epoch 4, batch 170, loss = 0.013078004121780396\n",
      "epoch 4, batch 180, loss = 0.015934469178318977\n",
      "epoch 4, batch 190, loss = 0.019726237282156944\n",
      "epoch 4, batch 200, loss = 0.01730591244995594\n",
      "epoch 4, batch 210, loss = 0.0073693739250302315\n",
      "epoch 4, batch 220, loss = 0.04294852912425995\n",
      "epoch 4, batch 230, loss = 0.027369573712348938\n",
      "epoch 4, batch 240, loss = 0.023930132389068604\n",
      "epoch 4, batch 250, loss = 0.045184578746557236\n",
      "epoch 4, batch 260, loss = 0.04173904284834862\n",
      "epoch 4, batch 270, loss = 0.015959372743964195\n",
      "epoch 4, batch 280, loss = 0.021887976676225662\n",
      "epoch 4, batch 290, loss = 0.011207780800759792\n",
      "epoch 5, batch 0, loss = 0.020719585940241814\n",
      "epoch 5, batch 10, loss = 0.0037267161533236504\n",
      "epoch 5, batch 20, loss = 0.0031753776129335165\n",
      "epoch 5, batch 30, loss = 0.004461726173758507\n",
      "epoch 5, batch 40, loss = 0.014273816719651222\n",
      "epoch 5, batch 50, loss = 0.04832948371767998\n",
      "epoch 5, batch 60, loss = 0.01852826029062271\n",
      "epoch 5, batch 70, loss = 0.03395453467965126\n",
      "epoch 5, batch 80, loss = 0.028307149186730385\n",
      "epoch 5, batch 90, loss = 0.022853786125779152\n",
      "epoch 5, batch 100, loss = 0.006503470707684755\n",
      "epoch 5, batch 110, loss = 0.009018379263579845\n",
      "epoch 5, batch 120, loss = 0.006181620992720127\n",
      "epoch 5, batch 130, loss = 0.007262693718075752\n",
      "epoch 5, batch 140, loss = 0.019925910979509354\n",
      "epoch 5, batch 150, loss = 0.006428847089409828\n",
      "epoch 5, batch 160, loss = 0.015974070876836777\n",
      "epoch 5, batch 170, loss = 0.011557814665138721\n",
      "epoch 5, batch 180, loss = 0.02332477644085884\n",
      "epoch 5, batch 190, loss = 0.0342191681265831\n",
      "epoch 5, batch 200, loss = 0.041594795882701874\n",
      "epoch 5, batch 210, loss = 0.010552879422903061\n",
      "epoch 5, batch 220, loss = 0.030778730288147926\n",
      "epoch 5, batch 230, loss = 0.02100975066423416\n",
      "epoch 5, batch 240, loss = 0.01247360184788704\n",
      "epoch 5, batch 250, loss = 0.00618350226432085\n",
      "epoch 5, batch 260, loss = 0.002852559322491288\n",
      "epoch 5, batch 270, loss = 0.08437160402536392\n",
      "epoch 5, batch 280, loss = 0.056349512189626694\n",
      "epoch 5, batch 290, loss = 0.017392875626683235\n",
      "epoch 6, batch 0, loss = 0.002151043154299259\n",
      "epoch 6, batch 10, loss = 0.02165919356048107\n",
      "epoch 6, batch 20, loss = 0.0077382540330290794\n",
      "epoch 6, batch 30, loss = 0.007216703146696091\n",
      "epoch 6, batch 40, loss = 0.005925602745264769\n",
      "epoch 6, batch 50, loss = 0.018836205825209618\n",
      "epoch 6, batch 60, loss = 0.013171345926821232\n",
      "epoch 6, batch 70, loss = 0.01471011247485876\n",
      "epoch 6, batch 80, loss = 0.006624539382755756\n",
      "epoch 6, batch 90, loss = 0.006036204285919666\n",
      "epoch 6, batch 100, loss = 0.047812320291996\n",
      "epoch 6, batch 110, loss = 0.008769772946834564\n",
      "epoch 6, batch 120, loss = 0.009687901474535465\n",
      "epoch 6, batch 130, loss = 0.0016112725716084242\n",
      "epoch 6, batch 140, loss = 0.008721751160919666\n",
      "epoch 6, batch 150, loss = 0.014414876699447632\n",
      "epoch 6, batch 160, loss = 0.017001761123538017\n",
      "epoch 6, batch 170, loss = 0.012552017346024513\n",
      "epoch 6, batch 180, loss = 0.004255066625773907\n",
      "epoch 6, batch 190, loss = 0.0387188158929348\n",
      "epoch 6, batch 200, loss = 0.0071315038949251175\n",
      "epoch 6, batch 210, loss = 0.010937826707959175\n",
      "epoch 6, batch 220, loss = 0.007706871256232262\n",
      "epoch 6, batch 230, loss = 0.028676722198724747\n",
      "epoch 6, batch 240, loss = 0.0036224538926035166\n",
      "epoch 6, batch 250, loss = 0.024768464267253876\n",
      "epoch 6, batch 260, loss = 0.012070263735949993\n",
      "epoch 6, batch 270, loss = 0.02181483991444111\n",
      "epoch 6, batch 280, loss = 0.008198260329663754\n",
      "epoch 6, batch 290, loss = 0.01917206309735775\n",
      "epoch 7, batch 0, loss = 0.02054082788527012\n",
      "epoch 7, batch 10, loss = 0.013725447468459606\n",
      "epoch 7, batch 20, loss = 0.007085865363478661\n",
      "epoch 7, batch 30, loss = 0.007671522442251444\n",
      "epoch 7, batch 40, loss = 0.006519374903291464\n",
      "epoch 7, batch 50, loss = 0.033358823508024216\n",
      "epoch 7, batch 60, loss = 0.01685291714966297\n",
      "epoch 7, batch 70, loss = 0.051798004657030106\n",
      "epoch 7, batch 80, loss = 0.0063198464922606945\n",
      "epoch 7, batch 90, loss = 0.022525984793901443\n",
      "epoch 7, batch 100, loss = 0.06319530308246613\n",
      "epoch 7, batch 110, loss = 0.032620467245578766\n",
      "epoch 7, batch 120, loss = 0.026971321552991867\n",
      "epoch 7, batch 130, loss = 0.020718207582831383\n",
      "epoch 7, batch 140, loss = 0.0020911453757435083\n",
      "epoch 7, batch 150, loss = 0.06725400686264038\n",
      "epoch 7, batch 160, loss = 0.003765815868973732\n",
      "epoch 7, batch 170, loss = 0.018930334597826004\n",
      "epoch 7, batch 180, loss = 0.017765242606401443\n",
      "epoch 7, batch 190, loss = 0.007815742865204811\n",
      "epoch 7, batch 200, loss = 0.021732212975621223\n",
      "epoch 7, batch 210, loss = 0.011699569411575794\n",
      "epoch 7, batch 220, loss = 0.01888645812869072\n",
      "epoch 7, batch 230, loss = 0.0029677841812372208\n",
      "epoch 7, batch 240, loss = 0.011574569158256054\n",
      "epoch 7, batch 250, loss = 0.007717551197856665\n",
      "epoch 7, batch 260, loss = 0.003862603334710002\n",
      "epoch 7, batch 270, loss = 0.005495042074471712\n",
      "epoch 7, batch 280, loss = 0.002788879908621311\n",
      "epoch 7, batch 290, loss = 0.004038780461996794\n",
      "epoch 8, batch 0, loss = 0.00812852755188942\n",
      "epoch 8, batch 10, loss = 0.00926963984966278\n",
      "epoch 8, batch 20, loss = 0.008831215091049671\n",
      "epoch 8, batch 30, loss = 0.01364386547356844\n",
      "epoch 8, batch 40, loss = 0.025331959128379822\n",
      "epoch 8, batch 50, loss = 0.002838479820638895\n",
      "epoch 8, batch 60, loss = 0.0020733089186251163\n",
      "epoch 8, batch 70, loss = 0.08013853430747986\n",
      "epoch 8, batch 80, loss = 0.01390205416828394\n",
      "epoch 8, batch 90, loss = 0.037235938012599945\n",
      "epoch 8, batch 100, loss = 0.016355762258172035\n",
      "epoch 8, batch 110, loss = 0.005184869281947613\n",
      "epoch 8, batch 120, loss = 0.008152625523507595\n",
      "epoch 8, batch 130, loss = 0.009442583657801151\n",
      "epoch 8, batch 140, loss = 0.018705621361732483\n",
      "epoch 8, batch 150, loss = 0.002148396335542202\n",
      "epoch 8, batch 160, loss = 0.0024105270858854055\n",
      "epoch 8, batch 170, loss = 0.0023002121597528458\n",
      "epoch 8, batch 180, loss = 0.009118269197642803\n",
      "epoch 8, batch 190, loss = 0.0017851580632850528\n",
      "epoch 8, batch 200, loss = 0.0040502301417291164\n",
      "epoch 8, batch 210, loss = 0.01721673645079136\n",
      "epoch 8, batch 220, loss = 0.021379223093390465\n",
      "epoch 8, batch 230, loss = 0.0020447312854230404\n",
      "epoch 8, batch 240, loss = 0.005690224934369326\n",
      "epoch 8, batch 250, loss = 0.002546830801293254\n",
      "epoch 8, batch 260, loss = 0.0074975998140871525\n",
      "epoch 8, batch 270, loss = 0.0030476038809865713\n",
      "epoch 8, batch 280, loss = 0.016148552298545837\n",
      "epoch 8, batch 290, loss = 0.05101989582180977\n",
      "epoch 9, batch 0, loss = 0.009408264420926571\n",
      "epoch 9, batch 10, loss = 0.0015724716940894723\n",
      "epoch 9, batch 20, loss = 0.009039171040058136\n",
      "epoch 9, batch 30, loss = 0.007869178429245949\n",
      "epoch 9, batch 40, loss = 0.02460254728794098\n",
      "epoch 9, batch 50, loss = 0.0014159813290461898\n",
      "epoch 9, batch 60, loss = 0.003926033154129982\n",
      "epoch 9, batch 70, loss = 0.0011756549356505275\n",
      "epoch 9, batch 80, loss = 0.01263827458024025\n",
      "epoch 9, batch 90, loss = 0.014350936748087406\n",
      "epoch 9, batch 100, loss = 0.01406536903232336\n",
      "epoch 9, batch 110, loss = 0.01889580674469471\n",
      "epoch 9, batch 120, loss = 0.004437969997525215\n",
      "epoch 9, batch 130, loss = 0.012523702345788479\n",
      "epoch 9, batch 140, loss = 0.005173663608729839\n",
      "epoch 9, batch 150, loss = 0.0115218386054039\n",
      "epoch 9, batch 160, loss = 0.0035226906184107065\n",
      "epoch 9, batch 170, loss = 0.00016443659842479974\n",
      "epoch 9, batch 180, loss = 0.00221803761087358\n",
      "epoch 9, batch 190, loss = 0.0069387792609632015\n",
      "epoch 9, batch 200, loss = 0.00294705294072628\n",
      "epoch 9, batch 210, loss = 0.004492562264204025\n",
      "epoch 9, batch 220, loss = 0.002208632417023182\n",
      "epoch 9, batch 230, loss = 0.0005640395684167743\n",
      "epoch 9, batch 240, loss = 0.019022366032004356\n",
      "epoch 9, batch 250, loss = 0.0004916231846436858\n",
      "epoch 9, batch 260, loss = 0.009155338630080223\n",
      "epoch 9, batch 270, loss = 0.02543972246348858\n",
      "epoch 9, batch 280, loss = 0.007412725128233433\n",
      "epoch 9, batch 290, loss = 0.007047825027257204\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    c = 0\n",
    "    for batch, (mini_batch_x, mini_batch_y) in enumerate(loader):\n",
    "        \n",
    "        if USE_CUDA:\n",
    "            mini_batch_x = mini_batch_x.cuda()\n",
    "            mini_batch_y = mini_batch_y.cuda()\n",
    "        pred = model(mini_batch_x)\n",
    "        lossfn = torch.nn.NLLLoss()\n",
    "        loss = lossfn(torch.log(pred), mini_batch_y)\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        if c % 10 == 0:\n",
    "            print(f\"epoch {epoch}, batch {batch}, loss = {loss.cpu().item()}\")\n",
    "        c = c + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了验证模型的效果，我们对前10个观测（即之前生成的 `smallx` 和 `smally`）进行预测。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 4 5 4 0 7 1 0 7 4]\n",
      "tensor([7, 4, 5, 4, 0, 7, 1, 0, 7, 4])\n"
     ]
    }
   ],
   "source": [
    "if USE_CUDA:\n",
    "    smallx = smallx.cuda()\n",
    "ypred = model(smallx)\n",
    "print(np.round(ypred.detach().cpu().numpy(), 3).argmax(axis=1))\n",
    "print(smally)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果模型搭建和训练都正常，那么每一行中概率最大的取值所在的位置应该正好对应真实的标签。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后，我们用模型对一些真实的手写数字图片进行预测。请你利用绘图软件（如 Windows 自带的绘图，或 Photoshop 等）准备10张正方形黑色底色的图片，每张用鼠标绘制一个数字（请使用较粗的笔划），从0到9，然后以0.png，1.png等文件名存储下来，放到当前目录一个名为 digits 的文件夹中。以下是几个例子：\n",
    "![](digits/sample0.png) ![](digits/sample5.png) ![](digits/sample8.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来利用 Pillow 软件包读取图片："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=261x261 at 0x1C4D437BE50>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "im = Image.open(\"digits/sample0.png\")\n",
    "im"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "此时如果直接将其转为 Numpy 数组会得到三个通道："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(261, 261, 3)\n"
     ]
    }
   ],
   "source": [
    "im_arr = np.array(im)\n",
    "print(im_arr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因此，我们先强制转换为灰度图片（单通道），再缩放至模型的图片大小 28 x 28："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABQElEQVR4nGNgoAlgROaIiop/5vny8cO7vxiSksEuwiyf+SQZ7+yd+4KBgYGBgQUmJRcQp3D/z8ebWmLvNIzlK94h6WQKyNf7+HbT9s+fBf4w2iRKxx5Csi3s9rvjkfJQDs+6l1FIxspksM9acAOmkomP7Q+EwcDAwMDgafxmDlyOge33z1cISSY1hhV3EXboqL5+jSQpwPjtP0JSUODeY4QkI9N/ToQckx7Lva9IdnJ8eIiQ1Av6dP4vQvL3nf/JEjA5sSyFuweQfMlgdO2NL5QpNOfVFXsGFND5Zo0SAwMDAwN74YuH/qhyDDpnPnQwMTAwMCTcu5fPjCbJGHn3ZhQDA3P4rQ/d3AzogL317a32oP4nbxeLYsgxMMivfvL9+ZdX85SQzYOzRAJtxa6d3vgNi0YGBgYGRjYmHDKDBQAAHZJkUSWMm9UAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x1C4DBC909D0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im = im.convert(\"L\")\n",
    "im.thumbnail((28, 28))\n",
    "im_arr = np.array(im)\n",
    "print(im_arr.shape)\n",
    "im"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了传递给模型对象，还需要先将数值归一化到 [0,1] 区间，转换为 PyTorch 的 Tensor 类型，并增加一个批次和一个通道的维度："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "test0 = torch.tensor(im_arr / 255.0, dtype=torch.float32).view(1, 1, 28, 28)\n",
    "print(test0.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后对图片标签进行预测："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.887 0.    0.015 0.    0.    0.    0.019 0.    0.    0.078]]\n"
     ]
    }
   ],
   "source": [
    "pred0 = model(test0)\n",
    "print(np.round(pred0.detach().cpu().numpy(), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "预测结果是否符合真实情形？请对你自己绘制出的10张图片进行类似的预测操作，并评价其效果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(char):\n",
    "    im = Image.open(\"digits/\"+char+\".png\")\n",
    "    im = im.convert(\"L\")\n",
    "    im.thumbnail((28, 28))\n",
    "    im_arr = np.array(im)\n",
    "    test0 = torch.tensor(im_arr / 255.0, dtype=torch.float32).view(1, 1, 28, 28)\n",
    "    if USE_CUDA:\n",
    "        test0 = test0.cuda()\n",
    "    pred0 = model(test0)\n",
    "    return np.round(pred0.detach().cpu().numpy(), 3).argmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "读不了图片会报错"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第2题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 目标：通过对英文名数据进行训练，构建一个 RNN 模型，实现英文名的自动生成。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 主要步骤：获取和整理数据，对字符串进行 one-hot 编码，创建模型结构，定义损失函数，编写训练循环，最后生成人名字符串。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 获取和整理数据。数据文件已存为 `data/names.txt`，先将其读取为字符串列表："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3668\n",
      "['Abbas', 'Abbey', 'Abbott', 'Abdi', 'Abel']\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "lines = io.open(\"data/names.txt\").read().strip().split('\\n')\n",
    "print(len(lines))\n",
    "print(lines[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看出，共读取了3668个名字。为了简单起见，我们将所有的大写字母转换为小写。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abbas', 'abbey', 'abbott', 'abdi', 'abel']\n"
     ]
    }
   ],
   "source": [
    "names = [s.lower() for s in lines]\n",
    "print(names[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来我们需要构建一个字符的字典。对于英文名来说很简单，即26个字母。我们可以通过下面的代码直接得到。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abcdefghijklmnopqrstuvwxyz'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "dict = string.ascii_lowercase\n",
    "dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 下面准备好 one-hot 编码所需的函数。编写函数 `char2index(char)`，将一个字母转换为其所在字典的位置。例如 `char2index(\"a\")` 要返回0，`char2index(\"z\")` 要返回25，等等。提示：使用字符串的 `.find()` 函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "def char2index(char):\n",
    "    # Implementation here\n",
    "    o_h = [x for x in dict]\n",
    "    return o_h.index(char)\n",
    "print(char2index(\"z\") == 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "编写 `char2tensor(char)` 函数，将一个字母转换为 one-hot 向量，即该向量中第 i 个元素为1，其余为0，其中 i 表示该字母在字典中的位置。\n",
    "\n",
    "**注意，该向量的长度应为27，因为我们要预留终止符，用 `[0.0, 0.0, ..., 1.0]` 表示**。\n",
    "\n",
    "`char2tensor(\"a\")` 应返回 `torch.tensor([1.0, 0.0, ...])`，`char2tensor(\"z\")` 应返回 `torch.tensor([0.0, ..., 1.0, 0.0])`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 0.])\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "def char2tensor(char):\n",
    "    # Implementation here\n",
    "    i = char2index(char)\n",
    "    res = torch.zeros(27)\n",
    "    res[i] = 1\n",
    "    return res\n",
    "\n",
    "print(char2tensor(\"a\"))\n",
    "print(char2tensor(\"z\"))\n",
    "print(char2tensor(\"z\").shape[0] == 27)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. 构建模型。我们使用最简单的 RNN 结构，即隐藏单元是输入和上一期隐藏单元的线性变换加上 Tanh 激活函数，输出单元是隐藏单元的线性变换加上 Softmax 激活函数。输出的结果代表下一个字符的概率分布。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "class RNN(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.i2h = ...\n",
    "        self.h2o = ...\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        combined = torch.cat((input, hidden), dim=1)\n",
    "        hidden = torch.tanh(self.i2h(combined))\n",
    "        output = torch.nn.functional.softmax(self.h2o(hidden), dim=1)\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "class RNN(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.i2h = torch.nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.h2o = torch.nn.Linear(hidden_size, 27)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        combined = torch.cat((input, hidden), dim=1)\n",
    "        hidden = torch.tanh(self.i2h(combined))\n",
    "        output = F.softmax(self.h2o(hidden), dim=1)\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们做一个简单的测试。请在下面的代码中加入适当的语句，使得每次运行的结果不变。根据其输出结果，请问当前模型预测字符a的下一个字符是什么？为什么？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0290, 0.0327, 0.0320, 0.0354, 0.0432, 0.0395, 0.0417, 0.0371, 0.0409,\n",
      "         0.0275, 0.0328, 0.0359, 0.0373, 0.0391, 0.0339, 0.0366, 0.0430, 0.0364,\n",
      "         0.0472, 0.0435, 0.0376, 0.0327, 0.0418, 0.0370, 0.0279, 0.0426, 0.0357]],\n",
      "       grad_fn=<SoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "rnn = RNN(input_size=27, hidden_size=10)\n",
    "input = char2tensor(\"a\")\n",
    "hidden = rnn.init_hidden()\n",
    "output, hidden = rnn(input.view(1, 27), hidden)\n",
    "print(output)\n",
    "#下一个字符是s 因为输出中的值最大"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. 接下来我们定义好损失函数。与第1题中类似，预测值是一个概率分布，而真实的标签是0到26中的一个整数，代表真实的下一个字符在字典中的位置。假设当前处理的名字为\"abel\"，那么字符a的输出结果对应的标签是什么？请完成下面的代码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.4199, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Change \"target\" to a proper value\n",
    "target = char2index('b')\n",
    "\n",
    "lossfn = torch.nn.NLLLoss()\n",
    "loss = lossfn(torch.log(output), torch.tensor([target]))\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. 明确单个字符的损失函数的计算方法后，请在下面计算出\"abel\"这个观测整体的损失函数值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.2938, grad_fn=<DivBackward0>)\n",
      "tensor(13.1751, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "word = 'abel'\n",
    "loss_sum = 0\n",
    "l = len(word)\n",
    "for i in range(l):\n",
    "    input = char2tensor(word[i])\n",
    "    output, hidden = rnn(input.view(1, 27), hidden)\n",
    "    lossfn = torch.nn.NLLLoss()\n",
    "    if i < l - 1:\n",
    "        target = char2index(word[i+1])\n",
    "    else:\n",
    "        target = 26\n",
    "    loss = lossfn(torch.log(output),  torch.tensor([target]))\n",
    "    loss_sum += loss\n",
    "print(loss_sum / l)\n",
    "print(loss_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. 将上述过程在数据上进行反复迭代，训练模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, obs 0, loss = 3.3991856575012207\n",
      "epoch 0, obs 1000, loss = 2.918344020843506\n",
      "epoch 0, obs 2000, loss = 2.6398532390594482\n",
      "epoch 0, obs 3000, loss = 3.1096529960632324\n",
      "epoch 1, obs 0, loss = 2.776276111602783\n",
      "epoch 1, obs 1000, loss = 2.5617995262145996\n",
      "epoch 1, obs 2000, loss = 2.415987014770508\n",
      "epoch 1, obs 3000, loss = 2.4527029991149902\n",
      "epoch 2, obs 0, loss = 2.5975751876831055\n",
      "epoch 2, obs 1000, loss = 2.585355520248413\n",
      "epoch 2, obs 2000, loss = 2.5821340084075928\n",
      "epoch 2, obs 3000, loss = 2.7673685550689697\n",
      "epoch 3, obs 0, loss = 2.584155559539795\n",
      "epoch 3, obs 1000, loss = 2.1915831565856934\n",
      "epoch 3, obs 2000, loss = 2.4389891624450684\n",
      "epoch 3, obs 3000, loss = 2.0150928497314453\n",
      "epoch 4, obs 0, loss = 2.4576306343078613\n",
      "epoch 4, obs 1000, loss = 2.9122250080108643\n",
      "epoch 4, obs 2000, loss = 2.5470449924468994\n",
      "epoch 4, obs 3000, loss = 2.1251466274261475\n",
      "epoch 5, obs 0, loss = 2.283302068710327\n",
      "epoch 5, obs 1000, loss = 2.564319133758545\n",
      "epoch 5, obs 2000, loss = 2.1136810779571533\n",
      "epoch 5, obs 3000, loss = 2.19895601272583\n",
      "epoch 6, obs 0, loss = 2.385223388671875\n",
      "epoch 6, obs 1000, loss = 2.7023868560791016\n",
      "epoch 6, obs 2000, loss = 2.240619659423828\n",
      "epoch 6, obs 3000, loss = 2.557904005050659\n",
      "epoch 7, obs 0, loss = 1.9776948690414429\n",
      "epoch 7, obs 1000, loss = 1.7167218923568726\n",
      "epoch 7, obs 2000, loss = 1.6471465826034546\n",
      "epoch 7, obs 3000, loss = 1.972745418548584\n",
      "epoch 8, obs 0, loss = 2.3119893074035645\n",
      "epoch 8, obs 1000, loss = 2.0465922355651855\n",
      "epoch 8, obs 2000, loss = 2.7650790214538574\n",
      "epoch 8, obs 3000, loss = 1.8902024030685425\n",
      "epoch 9, obs 0, loss = 2.1596932411193848\n",
      "epoch 9, obs 1000, loss = 2.3838236331939697\n",
      "epoch 9, obs 2000, loss = 2.1008870601654053\n",
      "epoch 9, obs 3000, loss = 3.150839328765869\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(123)\n",
    "torch.random.manual_seed(123)\n",
    "\n",
    "n = len(names)\n",
    "n_hidden = 16\n",
    "n_input = 27\n",
    "nepoch = 10\n",
    "\n",
    "rnn = RNN(n_input, n_hidden)\n",
    "opt = torch.optim.Adam(rnn.parameters(), lr=0.0001)\n",
    "train_ind = np.arange(n)\n",
    "losses = []\n",
    "\n",
    "lossfn = torch.nn.NLLLoss()\n",
    "\n",
    "# Loop over epochs\n",
    "for k in range(nepoch):\n",
    "    # Shuffle the data\n",
    "    np.random.shuffle(train_ind)\n",
    "    # Loop over observations. Each observation is a name\n",
    "    for i in range(n):\n",
    "        name = names[train_ind[i]]\n",
    "        nchar = len(name)\n",
    "        # Loop over the characters in the name\n",
    "        # Each input character has a target, which is the index of the next character in the dictionary\n",
    "        # For the last character in the name, the target is the end-of-sequence symbol, which has index 26\n",
    "        loss = 0\n",
    "        hidden = rnn.init_hidden()\n",
    "        for j in range(nchar):\n",
    "            input = char2tensor(name[j])\n",
    "            output, hidden = rnn(input.view(1, n_input), hidden)\n",
    "\n",
    "            if j == nchar - 1:\n",
    "                target = 26\n",
    "            else:\n",
    "                target = char2index(name[j + 1])\n",
    "\n",
    "            loss = loss + lossfn(torch.log(output), torch.tensor([target]))\n",
    "    \n",
    "        loss = loss / nchar\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "        if i % 1000 == 0:\n",
    "            print(f\"epoch {k}, obs {i}, loss = {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#所有画图的部分都运行不了\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. 编写一个函数 `random_first_letter()`，它随机返回字典中的一个字符，我们将利用它来随机生成第一个字符。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e\n",
      "n\n",
      "e\n"
     ]
    }
   ],
   "source": [
    "def random_first_letter():\n",
    "    # Implementation here\n",
    "    i = np.random.randint(0, 26)\n",
    "    return dict[i]\n",
    "\n",
    "print(random_first_letter())\n",
    "print(random_first_letter())\n",
    "print(random_first_letter())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "请简要说明如下的代码的含义（可以在代码中加入注释），然后利用它随机生成10个名字。评价生成的结果，并简要说明可以如何改进模型的效果？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_name(max_len=20):\n",
    "    rnn.eval()\n",
    "    first_letter = random_first_letter()\n",
    "    char_ind = [char2index(first_letter)]\n",
    "    input = char2tensor(first_letter)  #将字母转化为tensor 输入模型\n",
    "    hidden = rnn.init_hidden()\n",
    "    for i in range(max_len - 1):\n",
    "        output, hidden = rnn(input.view(1, n_input), hidden)\n",
    "        ind = torch.argmax(output).item()\n",
    "        if ind == 26:   # 当为终止符时，结束生成\n",
    "            break\n",
    "        char_ind.append(ind)\n",
    "        input.zero_()\n",
    "        input[ind] = 1.0\n",
    "    return \"\".join([dict[i] for i in char_ind]) #返回拼接后的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lane\n",
      "xarle\n",
      "garlen\n",
      "erer\n",
      "jarlen\n",
      "corlen\n",
      "arer\n",
      "zarlen\n",
      "qarlen\n",
      "warlen\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(random_name())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第3题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "利用卷积函数实现任意大整数的乘法。给定两个整数，如 183612 和 23333，用两个列表表达它们的序列："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "n1 = [1, 8, 3, 6, 1, 2]\n",
    "n2 = [2, 3, 3, 3, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "请编写一个函数 `integer_mult(n1, n2)`，返回 `n1 * n2` 对应的整数序列。注意不要直接调用乘法表达式（设想有两个非常大的整数，直接相乘可能会导致数值溢出）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "def integer_mult(n1, n2):\n",
    "    res = list(np.convolve(n1,n2))[::-1]\n",
    "    rem = 0\n",
    "    for i in range(len(res)):\n",
    "        res[i] = res[i] + rem\n",
    "        if res[i] > 10:\n",
    "            rem = int(str(res[i])[0])\n",
    "            res[i] = int(str(res[i])[1])\n",
    "    return res[::-1]\n",
    "\n",
    "res = integer_mult(n1, n2)\n",
    "print(res == [4, 2, 8, 4, 2, 1, 8, 7, 9, 6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "思路："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 先实现多项式的乘法。例如，给定 $p(x)=1+2x+x^4$ 和 $q(x)=x+3x^2+5x^3$，计算 $r(x)=p(x)q(x)$。我们将 $p(x)$ 编码为 `p = [1, 2, 0, 0, 1]`，$q(x)$ 编码为 `q = [0, 1, 3, 5]`，请编写函数 `poly_mult(p, q)`，使得 `poly_mult(p, q) == [0, 1, 5, 11, 10, 1, 3, 5]`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "p = [1, 2, 0, 0, 1]\n",
    "q = [0, 1, 3, 5]\n",
    "\n",
    "def poly_mult(p, q):\n",
    "    # Implementation here\n",
    "    n = len(p)\n",
    "    m = len(q)\n",
    "    L = np.array(p).reshape(-1,1).dot(np.array(q).reshape(1,-1))\n",
    "    res = [0] * (len(p) + len(q) - 1)\n",
    "    for i in range(n):\n",
    "        for j in range(m):\n",
    "            res[i + j] += L[i, j]\n",
    "    return res\n",
    "\n",
    "print(poly_mult(p, q) == [0, 1, 5, 11, 10,  1, 3, 5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 对于任意的一个整数，将其看成是某个多项式在 $x=10$ 处的取值，如 $123 = p_1(10)$，$p_1(x)=3+2x+x^2$，$5310 = p_2(10)$，$p_2(x)=x+3x^2+5x^3$，注意需要适当将序列反序。因此，要计算 $123\\times 5310$，相当于计算 $r(10)$ 的值，但为了避免直接进行乘法运算（防止溢出），可以先计算 $r(x)$ 的表达式（等价于其系数向量），然后建立起 $r(x)$ 的系数与 $r(10)$ 之间的联系（见如下第3点）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 如果一个多项式 $r(x)$ 所有的系数都是0到9之间的整数，那么 $r(x)$ 和 $r(10)$ 的关系非常直接，比如若 $r(x)=1+2x+5x^2+3x^3$，则 $r(10)=3521$。但如果有系数超过10，就需要考虑进位的影响，比如 $r(x)=1+11x+2x^2$，$r(10)=311$。此时可以从 $r(x)$ 的第一项开始逐项进位，构造一个新的多项式 $r'(x)=1+x+3x^2$，满足 $r'(10)=r(10)$，且 $r'(x)$ 所有的系数都不超过10。 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 综合利用以上信息，完成本题的算法编写。并测试 23742389754298365 * 809723950 的结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9214025846297658050701750\n"
     ]
    }
   ],
   "source": [
    "p = [int(x) for x in '23742389754298365']\n",
    "q = [int(x) for x in '809723950']\n",
    "print(''.join([str(x) for x in integer_mult(p, q)]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
